{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-09-30T14:07:02.461321Z",
     "end_time": "2023-09-30T14:07:02.844413Z"
    }
   },
   "outputs": [],
   "source": [
    "# Following script combines the annotation data with the time series data\n",
    "path = r'C:\\Users\\Grover\\Documents\\GitHub\\EZLabel\\true_annotations'\n",
    "dict_path = r'Z:\\mfk\\basty-projects\\tmp_results\\predictions\\ProboscisPumping\\bouts_dict.pkl'\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def process_row(row, dictionary, N):\n",
    "    df_dict = dictionary[row['name']]\n",
    "    df_dict_filtered = df_dict.drop(['start_index', 'stop_index', 'region'], axis=1)\n",
    "\n",
    "    trial_id = int(row['trial_id'])\n",
    "    peak_index = row['peak_index']\n",
    "\n",
    "    # New dictionary to store sliced data with column names\n",
    "    sliced_data_dict = {}\n",
    "\n",
    "    for col in df_dict_filtered.columns:\n",
    "        if peak_index-N >= 0 and peak_index+N <= len(df_dict_filtered.loc[trial_id, col]):\n",
    "            start = max(0, peak_index - N)\n",
    "            end = min(len(df_dict_filtered.loc[trial_id, col]), peak_index + N)\n",
    "            sliced_data_dict[col] = df_dict_filtered.loc[trial_id, col][start:end]\n",
    "\n",
    "    return sliced_data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "pkl_files = glob.glob(os.path.join(path, '*.pkl'))\n",
    "ts_dict = pd.read_pickle(dict_path)\n",
    "\n",
    "df_list = []  # A list to store each DataFrame\n",
    "\n",
    "\n",
    "for file in pkl_files:\n",
    "    data = pd.read_pickle(file)\n",
    "    df = pd.DataFrame(data)\n",
    "    df['name'] = os.path.splitext(os.path.basename(file))[0]\n",
    "    df_list.append(df)  # Append the DataFrame to the list\n",
    "\n",
    "# Concatenate all the DataFrames in the list into a single DataFrame\n",
    "annotations = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Rename the columns to make it more intuitive\n",
    "annotations.rename(columns = {'index':'peak_index','column':'trial_id'},inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-30T14:07:12.181945Z",
     "end_time": "2023-09-30T14:07:23.778105Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "      peak_index        value trial_id                 name\n0            534  1014.361120        0       Fly05182022_5d\n1            694  1017.733769        0       Fly05182022_5d\n2            903  1027.228163        0       Fly05182022_5d\n3           1207  1021.721591        0       Fly05182022_5d\n4           1623  1023.545935        0       Fly05182022_5d\n...          ...          ...      ...                  ...\n8486         835   387.119720       22  Fly08032022_6d_SD_B\n8487         905   386.726096       22  Fly08032022_6d_SD_B\n8488         966   389.234434       22  Fly08032022_6d_SD_B\n8489        1041   504.997931       22  Fly08032022_6d_SD_B\n8490        1140   387.304468       22  Fly08032022_6d_SD_B\n\n[8491 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>peak_index</th>\n      <th>value</th>\n      <th>trial_id</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>534</td>\n      <td>1014.361120</td>\n      <td>0</td>\n      <td>Fly05182022_5d</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>694</td>\n      <td>1017.733769</td>\n      <td>0</td>\n      <td>Fly05182022_5d</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>903</td>\n      <td>1027.228163</td>\n      <td>0</td>\n      <td>Fly05182022_5d</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1207</td>\n      <td>1021.721591</td>\n      <td>0</td>\n      <td>Fly05182022_5d</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1623</td>\n      <td>1023.545935</td>\n      <td>0</td>\n      <td>Fly05182022_5d</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8486</th>\n      <td>835</td>\n      <td>387.119720</td>\n      <td>22</td>\n      <td>Fly08032022_6d_SD_B</td>\n    </tr>\n    <tr>\n      <th>8487</th>\n      <td>905</td>\n      <td>386.726096</td>\n      <td>22</td>\n      <td>Fly08032022_6d_SD_B</td>\n    </tr>\n    <tr>\n      <th>8488</th>\n      <td>966</td>\n      <td>389.234434</td>\n      <td>22</td>\n      <td>Fly08032022_6d_SD_B</td>\n    </tr>\n    <tr>\n      <th>8489</th>\n      <td>1041</td>\n      <td>504.997931</td>\n      <td>22</td>\n      <td>Fly08032022_6d_SD_B</td>\n    </tr>\n    <tr>\n      <th>8490</th>\n      <td>1140</td>\n      <td>387.304468</td>\n      <td>22</td>\n      <td>Fly08032022_6d_SD_B</td>\n    </tr>\n  </tbody>\n</table>\n<p>8491 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-30T14:07:40.904922Z",
     "end_time": "2023-09-30T14:07:40.947550Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "annotations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-17T21:14:10.191594Z",
     "end_time": "2023-07-17T21:14:10.203233Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create an empty DataFrame to store all the processed rows\n",
    "processed_data_df = pd.DataFrame()\n",
    "\n",
    "# Initialize a counter for slice\n",
    "slice_counter = 0\n",
    "\n",
    "# Loop through each row in annotations\n",
    "for i, row in annotations.iterrows():\n",
    "    processed_row = process_row(row, ts_dict, 30)\n",
    "\n",
    "    # Create a DataFrame for this row\n",
    "    row_df = pd.DataFrame(processed_row)\n",
    "\n",
    "    # Add 'slice_id' to the DataFrame\n",
    "    row_df['slice_id'] = slice_counter\n",
    "\n",
    "    # Set a multi-index using 'name', 'slice_id' and the existing index of row_df\n",
    "    row_df.index = pd.MultiIndex.from_tuples([(row['name'], slice_counter, i) for i in row_df.index],\n",
    "                                             names=['name', 'slice_id', 'time'])\n",
    "\n",
    "    # Append it to processed_data_df\n",
    "    processed_data_df = pd.concat([processed_data_df, row_df])\n",
    "\n",
    "    # Increment the slice_counter\n",
    "    slice_counter += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T12:11:05.362211Z",
     "end_time": "2023-09-29T12:15:40.800013Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create a dictionary where key is (name, slice_id) and value is the sub-DataFrame\n",
    "df_dict = dict(tuple(processed_data_df.groupby(level=['name', 'slice_id'])))\n",
    "\n",
    "# Initialize an empty list to store each 2D array\n",
    "array_list = []\n",
    "\n",
    "# Loop over the dictionary\n",
    "for key in df_dict:\n",
    "    # Convert each DataFrame to a 2D numpy array and append to list\n",
    "    array_list.append(df_dict[key].values)\n",
    "\n",
    "# Convert list of arrays to a 3D numpy array\n",
    "np_array = np.stack(array_list)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-17T21:09:25.977852Z",
     "end_time": "2023-07-17T21:09:26.178424Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "output_path = r'C:\\Users\\Grover\\Documents\\GitHub\\EZLabel'\n",
    "\n",
    "processed_data_df.to_pickle(os.path.join(output_path,'false_peak_annotations.pkl'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-17T21:09:41.821670Z",
     "end_time": "2023-07-17T21:09:41.837043Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save(os.path.join(output_path,'false_peak_annotations.npy'),np_array)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-17T21:09:43.591205Z",
     "end_time": "2023-07-17T21:09:43.647218Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "output_path = r'C:\\Users\\Grover\\Documents\\GitHub\\EZLabel\\true_annotations\\output'\n",
    "annotations.to_pickle(os.path.join(output_path,'true_annotations.pkl'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-30T14:07:59.459934Z",
     "end_time": "2023-09-30T14:07:59.470809Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "annotations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-17T21:23:32.179840Z",
     "end_time": "2023-07-17T21:23:32.189841Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch all .mp4 files from the directory\n",
    "directory = r'Y:\\DeepSleepPaperData\\Annotated\\PredictedVideos\\Pumping'\n",
    "file_names = [f for f in os.listdir(directory) if f.endswith('.mp4')]\n",
    "\n",
    "# Process each filename\n",
    "data = []\n",
    "\n",
    "for file in file_names:\n",
    "    parts = file.split(\"_\")\n",
    "\n",
    "    index_position = parts.index('index')\n",
    "    name = \"_\".join(parts[:index_position])\n",
    "    trial_id = int(parts[index_position + 1])\n",
    "    start = int(parts[parts.index('start') + 1])\n",
    "\n",
    "    data.append([name, trial_id, start])\n",
    "\n",
    "# Construct the DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"name\", \"trial_id\", \"start\"])\n",
    "\n",
    "print(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T12:17:56.438251Z",
     "end_time": "2023-09-29T12:17:56.640606Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(annotations)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T12:19:40.211909Z",
     "end_time": "2023-09-29T12:19:40.218909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "annotations['trial_id'] = annotations['trial_id'].astype('int64')\n",
    "df['trial_id'] = df['trial_id'].astype('int64')\n",
    "\n",
    "\n",
    "# Merging dataframes on 'name' and 'trial_id'\n",
    "merged_df = annotations.merge(df[['name', 'trial_id', 'start']], on=['name', 'trial_id'], how='left')\n",
    "\n",
    "print(merged_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T12:23:20.899440Z",
     "end_time": "2023-09-29T12:23:20.936879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df['pump_pos'] = merged_df['peak_index'] + merged_df['start']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T12:24:09.557797Z",
     "end_time": "2023-09-29T12:24:09.576801Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T12:24:12.717474Z",
     "end_time": "2023-09-29T12:24:12.736478Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df.to_csv('merged_annot.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T12:26:08.620259Z",
     "end_time": "2023-09-29T12:26:08.661268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(merged_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T12:33:31.327458Z",
     "end_time": "2023-09-29T12:33:31.419622Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "expt_info_df_path = r'Z:\\mfk\\basty-projects\\expt_info_df.pkl'\n",
    "expt_info_df = pd.read_pickle(expt_info_df_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T12:36:41.931080Z",
     "end_time": "2023-09-29T12:36:41.973089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "expt_info_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T12:36:44.261774Z",
     "end_time": "2023-09-29T12:36:44.292781Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def generate_tick_data(FPS=30, sd=False):\n",
    "\n",
    "    if sd == False:\n",
    "        xticks = np.arange(\n",
    "            start=0, stop=FPS * 60 * 60 * 16 + 1, step=FPS * 60 * 60 * 2\n",
    "        )\n",
    "        ZT_ticks = xticks\n",
    "        ZT_ticklabels = [\n",
    "            \"ZT\" + str((tick + 10) % 24) for tick in range(0, len(xticks) * 2, 2)\n",
    "        ]\n",
    "    else:\n",
    "        xticks = np.arange(\n",
    "            start=0, stop=FPS * 60 * 60 * 6 + 1, step=FPS * 60 * 60 * 1\n",
    "        )\n",
    "        ZT_ticks = xticks\n",
    "        ZT_ticklabels = [\n",
    "            \"ZT\" + str(tick) for tick in range(0, len(xticks) * 1, 1)\n",
    "        ]\n",
    "\n",
    "    return ZT_ticks, ZT_ticklabels\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T13:05:03.508419Z",
     "end_time": "2023-09-29T13:05:03.529626Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Create a dictionary to map names to SD values from expt_info_df\n",
    "name_to_sd = dict(zip(expt_info_df['ExptNames'], expt_info_df['SD']))\n",
    "\n",
    "# Split df into two based on SD value\n",
    "df_sd_true = df[df['name'].map(name_to_sd)]\n",
    "df_sd_false = df[~df['name'].map(name_to_sd)]\n",
    "\n",
    "# Initialize subplots\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(10, len(df['name'].unique())))\n",
    "\n",
    "# Function to plot given a subset of df\n",
    "def plot_subset(subset_df, ax, color):\n",
    "    unique_names = subset_df['name'].unique()\n",
    "    for idx, name in enumerate(unique_names):\n",
    "        sub_subset_df = subset_df[subset_df['name'] == name]\n",
    "        for _, row in sub_subset_df.iterrows():\n",
    "            pump_pos = row['pump_pos']\n",
    "            ax.barh(idx, 60, left=pump_pos - 30, color=color, edgecolor='none')\n",
    "    ax.set_yticks(range(len(unique_names)))\n",
    "    ax.set_yticklabels(unique_names, rotation=0)  # Consider rotating y-tick labels if they overlap\n",
    "\n",
    "# Plot\n",
    "plot_subset(df_sd_true, axes[0], '#377eb8')\n",
    "plot_subset(df_sd_false, axes[1], '#d62728')\n",
    "\n",
    "ZT_ticks, ZT_ticklabels = generate_tick_data(30, sd=True)\n",
    "axes[0].set_xticks(ZT_ticks)\n",
    "axes[0].set_xticklabels(ZT_ticklabels)  # Set x-tick labels for SD = True\n",
    "\n",
    "ZT_ticks, ZT_ticklabels = generate_tick_data(30, sd=False)\n",
    "axes[1].set_xticks(ZT_ticks)\n",
    "axes[1].set_xticklabels(ZT_ticklabels)  # Set x-tick labels for SD = False\n",
    "\n",
    "axes[0].set_title('SD = True')\n",
    "axes[1].set_title('SD = False')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Compact_Pump_Positions.pdf')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T13:05:38.897500Z",
     "end_time": "2023-09-29T13:05:53.892949Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a dictionary to map names to SD values from expt_info_df\n",
    "name_to_sd = dict(zip(expt_info_df['ExptNames'], expt_info_df['SD']))\n",
    "\n",
    "# Helper function to plot given a subset of df\n",
    "def plot_data(subset_df, color, sd):\n",
    "    fig, ax = plt.subplots(figsize=(10, len(subset_df['name'].unique())))\n",
    "    unique_names = subset_df['name'].unique()\n",
    "\n",
    "    for idx, name in enumerate(unique_names):\n",
    "        sub_subset_df = subset_df[subset_df['name'] == name]\n",
    "        for _, row in sub_subset_df.iterrows():\n",
    "            pump_pos = row['pump_pos']\n",
    "            ax.barh(idx, 60, left=pump_pos - 30, color=color, edgecolor='none')\n",
    "\n",
    "    ax.set_yticks(range(len(unique_names)))\n",
    "    ax.set_yticklabels(unique_names)\n",
    "\n",
    "    ZT_ticks, ZT_ticklabels = generate_tick_data(30, sd=sd)\n",
    "    ax.set_xticks(ZT_ticks)\n",
    "    ax.set_xticklabels(ZT_ticklabels)\n",
    "\n",
    "    title = 'SD = True' if sd else 'SD = False'\n",
    "    ax.set_title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'Pump_Positions_{title}.pdf')\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot data for SD = True\n",
    "def plot_sd_true():\n",
    "    df_sd_true = df[df['name'].map(name_to_sd)]\n",
    "    plot_data(df_sd_true, '#377eb8', sd=True)\n",
    "\n",
    "\n",
    "# Function to plot data for SD = False\n",
    "def plot_sd_false():\n",
    "    df_sd_false = df[~df['name'].map(name_to_sd)]\n",
    "    plot_data(df_sd_false, '#d62728', sd=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T13:06:27.266351Z",
     "end_time": "2023-09-29T13:06:27.277424Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_sd_true()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T13:06:33.007691Z",
     "end_time": "2023-09-29T13:06:37.737799Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract pump_pos values for SD=True and SD=False\n",
    "pump_pos_sd_true = df[df['name'].map(name_to_sd)]['pump_pos']\n",
    "pump_pos_sd_false = df[~df['name'].map(name_to_sd)]['pump_pos']\n",
    "\n",
    "# Initialize a figure with two subplots\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(10, 10))\n",
    "\n",
    "# Plot histogram for SD=True\n",
    "axes[0].hist(pump_pos_sd_true, bins=12, color='#377eb8', edgecolor='black')\n",
    "axes[0].set_title('Histogram of pump_pos (SD=True)')\n",
    "axes[0].set_xlabel('pump_pos values')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "ZT_ticks, ZT_ticklabels = generate_tick_data(30, sd=True)\n",
    "axes[0].set_xticks(ZT_ticks)\n",
    "axes[0].set_xticklabels(ZT_ticklabels)\n",
    "\n",
    "# Plot histogram for SD=False\n",
    "axes[1].hist(pump_pos_sd_false, bins=32, color='#d62728', edgecolor='black')\n",
    "axes[1].set_title('Histogram of pump_pos (SD=False)')\n",
    "axes[1].set_xlabel('pump_pos values')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "ZT_ticks, ZT_ticklabels = generate_tick_data(30, sd=False)\n",
    "axes[1].set_xticks(ZT_ticks)\n",
    "axes[1].set_xticklabels(ZT_ticklabels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Pump_Positions_Histograms.pdf')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T13:08:51.646110Z",
     "end_time": "2023-09-29T13:08:52.179822Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to compute histograms for each group (name)\n",
    "def compute_histograms(grouped_data, bins):\n",
    "    histograms = {}\n",
    "    for name, group in grouped_data:\n",
    "        counts, _ = np.histogram(group['pump_pos'], bins=bins)\n",
    "        histograms[name] = counts\n",
    "    return histograms\n",
    "\n",
    "FPS = 30\n",
    "# Define bin edges\n",
    "bins_sd_true = np.linspace(0, FPS * 60 * 60 * 6, 13) # 12 bins\n",
    "bins_sd_false = np.linspace(0, FPS * 60 * 60 * 16, 33) # 32 bins\n",
    "\n",
    "# Group data by 'name' and 'SD' condition\n",
    "grouped_sd_true = df[df['name'].map(name_to_sd)].groupby('name')\n",
    "grouped_sd_false = df[~df['name'].map(name_to_sd)].groupby('name')\n",
    "\n",
    "# Compute histograms for each group\n",
    "histograms_sd_true = compute_histograms(grouped_sd_true, bins_sd_true)\n",
    "histograms_sd_false = compute_histograms(grouped_sd_false, bins_sd_false)\n",
    "\n",
    "# Plot histograms (Here, I'm plotting aggregated histograms for demonstration)\n",
    "fig, axes = plt.subplots(nrows=2, figsize=(10, 10))\n",
    "\n",
    "axes[0].bar(bins_sd_true[:-1], np.nanmean(list(histograms_sd_true.values()), axis=0),\n",
    "            width=np.diff(bins_sd_true), align=\"edge\", color='#377eb8', edgecolor='black')\n",
    "axes[0].set_title('Aggregated Histogram of pump_pos (SD=True)')\n",
    "axes[0].set_xlabel('pump_pos values')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_xticks(bins_sd_true)\n",
    "ZT_ticks, ZT_ticklabels = generate_tick_data(30, sd=True)\n",
    "axes[0].set_xticks(ZT_ticks)\n",
    "axes[0].set_xticklabels(ZT_ticklabels)\n",
    "\n",
    "axes[1].bar(bins_sd_false[:-1], np.nanmean(list(histograms_sd_false.values()), axis=0),\n",
    "            width=np.diff(bins_sd_false), align=\"edge\", color='#d62728', edgecolor='black')\n",
    "axes[1].set_title('Aggregated Histogram of pump_pos (SD=False)')\n",
    "axes[1].set_xlabel('pump_pos values')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_xticks(bins_sd_false)\n",
    "ZT_ticks, ZT_ticklabels = generate_tick_data(30, sd=False)\n",
    "axes[1].set_xticks(ZT_ticks)\n",
    "axes[1].set_xticklabels(ZT_ticklabels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Aggregated_Pump_Positions_Histograms.pdf')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T13:28:46.016886Z",
     "end_time": "2023-09-29T13:28:46.600624Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name_to_sd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T13:44:47.523531Z",
     "end_time": "2023-09-29T13:44:47.539565Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_unique_names_sd_true = len(grouped_sd_true.groups)\n",
    "num_unique_names_sd_false = len(grouped_sd_false.groups)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T13:47:59.716103Z",
     "end_time": "2023-09-29T13:47:59.731107Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_unique_names_sd_false"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T13:48:05.631777Z",
     "end_time": "2023-09-29T13:48:05.657506Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_unique_names_sd_true"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-29T13:48:10.243581Z",
     "end_time": "2023-09-29T13:48:10.268647Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
